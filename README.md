# Projeto de Business Intelligence e Engenharia de Dados | E-commerce Olist

## Status do Projeto: Fase 2 Conclu√≠da ‚úÖ

Este projeto demonstra a constru√ß√£o de uma solu√ß√£o de dados ponta a ponta, desde a ingest√£o e processamento local at√© a migra√ß√£o e an√°lise em um ambiente de nuvem robusto e escal√°vel. A **Fase 1 (Arquitetura Local)** e a **Fase 2 (Migra√ß√£o para Nuvem e Dashboard de Log√≠stica)** est√£o conclu√≠das. A pr√≥xima etapa ser√° o desenvolvimento do dashboard Financeiro.

## Vis√£o Geral do Projeto

Este projeto apresenta uma solu√ß√£o completa de BI e Engenharia de Dados para an√°lise do dataset Olist. O objetivo √© transformar dados brutos de e-commerce em insights acion√°veis, cobrindo diferentes √°reas de neg√≥cio e evoluindo de uma arquitetura local para uma solu√ß√£o *serverless* na Google Cloud Platform (GCP).

## Problema de Neg√≥cio

O principal desafio √© responder a perguntas de neg√≥cio cruciais para diferentes √°reas da empresa ‚Äî como Marketing, Log√≠stica e Finan√ßas ‚Äî permitindo uma tomada de decis√£o √°gil e orientada por dados.

## Arquitetura da Solu√ß√£o

### Fase 1: Arquitetura Local (Implementada)
- **Fluxo:** `Arquivos CSV` -> `Jupyter/Python (ETL)` -> `MySQL (Camadas Silver/Gold)` -> `Power BI (Visualiza√ß√£o)`
- **Descri√ß√£o:** Um pipeline de dados inicial que processa os arquivos CSV, aplica transforma√ß√µes e os armazena em um banco de dados MySQL.

### Fase 2: Arquitetura em Nuvem (Implementada)
- **Fluxo:** `Python Script (ETL)` -> `GCS (Landing Zone)` -> `BigQuery (Data Warehouse com camadas Silver/Gold)` -> `Power BI (Visualiza√ß√£o)`
- **Descri√ß√£o:** Evolu√ß√£o da solu√ß√£o para uma arquitetura *serverless* e escal√°vel na GCP. Scripts em Python migraram os dados para o Google Cloud Storage (GCS). De l√°, foram carregados no BigQuery, que atua como Data Warehouse central. Para otimizar as consultas, foram criadas *views materializadas* na camada Gold.

## Tecnologias Utilizadas

- **Linguagem:** Python 3
- **Bibliotecas de ETL:** Pandas, SQLAlchemy, pandas-gbq
- **Banco de Dados (Fase 1):** MySQL
- **Cloud & Data Warehouse (Fase 2):** Google Cloud Platform (GCP), Google Cloud Storage (GCS), Google BigQuery
- **Business Intelligence:** Microsoft Power BI

## Dashboards Desenvolvidos

### 1. Dashboard de Marketing
- Focado em analisar a performance de vendas, canais de aquisi√ß√£o e perfil de clientes.

### 2. Dashboard de Log√≠stica üìä
- Projetado para transformar dados brutos de entrega em insights para otimizar a opera√ß√£o. Responde a perguntas de neg√≥cio como:
    - *"Onde est√£o nossos gargalos de entrega?"*
    - *"Nossas entregas s√£o eficientes em rela√ß√£o ao SLA?"*
    - *"O custo do frete se justifica pela velocidade?"*
- **KPIs e An√°lises Principais:**
    - **Monitoramento de SLA:** Entregas no prazo vs. Atrasadas.
    - **An√°lise de Gargalos:** Decomp√µe o tempo de entrega em fases (aprova√ß√£o, preparo, transporte) para identificar a maior demora por estado (UF).
    - **Custo vs. Tempo:** Gr√°fico de dispers√£o que analisa a correla√ß√£o entre o valor do frete e a velocidade da entrega.
    - **Performance Temporal:** Evolu√ß√£o da efici√™ncia log√≠stica ao longo dos anos.

## Como Executar

### Vers√£o 2 (Nuvem - GCP)
A execu√ß√£o deste pipeline ocorre em ambiente de nuvem. Os principais passos s√£o:
1.  **Ingest√£o:** Os dados tratados s√£o enviados para um bucket no Google Cloud Storage.
2.  **Data Warehouse:** O BigQuery √© populado com os dados do GCS, onde as tabelas das camadas Silver e Gold s√£o criadas.
3.  **Visualiza√ß√£o:** O Power BI se conecta diretamente ao BigQuery para consumir os dados e alimentar os dashboards de Marketing e Log√≠stica.

### Vers√£o 1 (Local)
1.  **Pr√©-requisitos:** Python 3.x, MySQL Server e Power BI Desktop instalados.
2.  **Clone o reposit√≥rio:** `git clone https://github.com/leanttro/kaggle_ecommerce_pipeline.git`
3.  **Instale as depend√™ncias:** `pip install pandas sqlalchemy mysql-connector-python`
4.  **Execute o ETL:** Configure suas credenciais do MySQL no notebook e execute-o para popular o banco de dados local.
5.  **Visualize:** Abra o arquivo `.pbix` e conecte o dashboard ao seu banco de dados MySQL.

## Pr√≥ximos Passos

- [ ] **Fase 3 [FINANCEIRO]:** Desenvolvimento de um novo dashboard focado em an√°lise financeira, respondendo perguntas sobre receita, ticket m√©dio, custos de frete e comiss√£o.
- [ ] Construir o pipeline de dados para a camada financeira no BigQuery.
- [ ] Documentar a modelagem e as regras de neg√≥cio da √°rea Financeira.

## Autor

**Leandro Andrade de Oliveira**
- **LinkedIn:** [linkedin.com/in/leanttro/](https://www.linkedin.com/in/leanttro/)
